{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from torchmetrics import AUROC\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchfm.dataset.avazu import AvazuDataset\n",
    "from torchfm.dataset.criteo import CriteoDataset\n",
    "from torchfm.dataset.movielens import MovieLens1MDataset, MovieLens20MDataset\n",
    "\n",
    "from torchfm.model.dcn import DeepCrossNetworkModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from torchfm.model.fm import FactorizationMachineModel\n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.afm import AttentionalFactorizationMachineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "batch_size = 512\n",
    "auroc = AUROC(task=\"binary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name, path):\n",
    "    if name == 'movielens1M':\n",
    "        return MovieLens1MDataset(path)\n",
    "    elif name == 'movielens20M':\n",
    "        return MovieLens20MDataset(path)\n",
    "    elif name == 'criteo':\n",
    "        return CriteoDataset(path)\n",
    "    elif name == 'avazu':\n",
    "        return AvazuDataset(path)\n",
    "    else:\n",
    "        raise ValueError('unknown dataset name: ' + name)\n",
    "\n",
    "def get_model(name, dataset):\n",
    "    field_dims = dataset.field_dims\n",
    "    if name == 'fm':\n",
    "        return FactorizationMachineModel(field_dims, embed_dim=16)\n",
    "    elif name == 'wd':\n",
    "        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'dcn':\n",
    "        return DeepCrossNetworkModel(field_dims, embed_dim=16, num_layers=3, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'dfm':\n",
    "        return DeepFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'afm':\n",
    "        return AttentionalFactorizationMachineModel(field_dims, embed_dim=16, LNN_dim=1500, mlp_dims=(400, 400, 400), dropouts=(0, 0, 0))\n",
    "    else:\n",
    "        raise ValueError('unknown model name: ' + name)\n",
    "\n",
    "\n",
    "class EarlyStopper(object):\n",
    "    def __init__(self, num_trials, save_path):\n",
    "        self.num_trials = num_trials\n",
    "        self.trial_counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def is_continuable(self, model, accuracy):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            self.trial_counter = 0\n",
    "            torch.save(model, self.save_path)\n",
    "            return True\n",
    "        elif self.trial_counter + 1 < self.num_trials:\n",
    "            self.trial_counter += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    targets, predicts = [], []\n",
    "    with torch.no_grad():\n",
    "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.cpu())\n",
    "            predicts.extend(y.cpu())\n",
    "        targets = torch.FloatTensor(targets).squeeze()\n",
    "        predicts = torch.FloatTensor(predicts).squeeze()\n",
    "    return auroc(predicts, targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terrorch.terrorch import Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './chkpt/'\n",
    "dataset_names = ['movielens1M', 'movielens20M', 'criteo']\n",
    "dataset_paths = ['D://Datasets//Rec//ml-1m//ratings.dat', 'D://Datasets//Rec//MovieLens20M//rating.csv', 'D://Datasets//Rec//criteo-dac//train.txt']\n",
    "model_paths = ['fm', 'dcn', 'afm', 'wd', 'dfm']\n",
    "datasets = ['_movielens1M.pt', '_movielens20M.pt', '_criteo.pt']\n",
    "bers = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, ]\n",
    "bers = bers[::-1]\n",
    "folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ]\n",
    "\n",
    "results = torch.zeros(size = (len(model_paths), len(datasets), len(bers), len(folds)))\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for dataset_i, dataset in enumerate(datasets):\n",
    "        test_data_loader = testset_prepare(dataset_names[dataset_i], dataset_paths[dataset_i])\n",
    "        for model_path_i, model_path in enumerate(model_paths):\n",
    "            for ber_i, ber in enumerate(bers):\n",
    "                for fold_i, fold in enumerate(folds):\n",
    "                    model = torch.load(base_dir + model_path + dataset)\n",
    "                    model = model.float().eval().to(device)\n",
    "                    injector = Injector(ber, param_names = ['mlp', 'fc', 'afm'], device = device, verbose = False)\n",
    "                    injector.inject(model)\n",
    "                    del injector\n",
    "                    result = test(model, test_data_loader, device)\n",
    "                    print(cnt, result)\n",
    "                    results[model_path_i][dataset_i][ber_i][fold_i] = result\n",
    "                    cnt += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Activation Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './chkpt/'\n",
    "dataset_names = ['movielens1M', 'movielens20M', 'criteo']\n",
    "dataset_paths = ['D://Datasets//Rec//ml-1m//ratings.dat', 'D://Datasets//Rec//MovieLens20M//rating.csv', 'D://Datasets//Rec//criteo-dac//train.txt']\n",
    "model_paths = ['fm', 'dcn', 'afm', 'wd', 'dfm']\n",
    "datasets = ['_movielens1M.pt', '_movielens20M.pt', '_criteo.pt']\n",
    "bers = [1e-2, 1e-3, 1e-4, 1e-5,]\n",
    "bers = bers[::-1]\n",
    "folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ]\n",
    "\n",
    "results = torch.zeros(size = (len(model_paths), len(datasets), len(bers), len(folds)))\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for dataset_i, dataset in enumerate(datasets):\n",
    "        test_data_loader = testset_prepare(dataset_names[dataset_i], dataset_paths[dataset_i])\n",
    "        for model_path_i, model_path in enumerate(model_paths):\n",
    "            for ber_i, ber in enumerate(bers):\n",
    "                for fold_i, fold in enumerate(folds):\n",
    "                    model = torch.load(base_dir + model_path + dataset)\n",
    "                    model = model.float().eval().to(device)\n",
    "                    injector = Injector(ber, param_names = ['mlp', 'fc', 'afm'], device = device, verbose = False, mitigation = 'clip')\n",
    "                    injector.inject(model)\n",
    "                    injector.perform_mitigation(model)\n",
    "                    del injector\n",
    "                    result = test(model, test_data_loader, device)\n",
    "                    print(cnt, result)\n",
    "                    results[model_path_i][dataset_i][ber_i][fold_i] = result\n",
    "                    cnt += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selective Bit Protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './chkpt/'\n",
    "dataset_names = ['movielens1M', 'movielens20M', 'criteo']\n",
    "dataset_paths = ['D://Datasets//Rec//ml-1m//ratings.dat', 'D://Datasets//Rec//MovieLens20M//rating.csv', 'D://Datasets//Rec//criteo-dac//train.txt']\n",
    "model_paths = ['fm', 'dcn', 'afm', 'wd', 'dfm']\n",
    "datasets = ['_movielens1M.pt', '_movielens20M.pt', '_criteo.pt']\n",
    "bers = [1e-2, 1e-3, 1e-4, 1e-5,]\n",
    "bers = bers[::-1]\n",
    "folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ]\n",
    "\n",
    "results = torch.zeros(size = (len(model_paths), len(datasets), len(bers), len(folds)))\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for dataset_i, dataset in enumerate(datasets):\n",
    "        test_data_loader = testset_prepare(dataset_names[dataset_i], dataset_paths[dataset_i])\n",
    "        for model_path_i, model_path in enumerate(model_paths):\n",
    "            for ber_i, ber in enumerate(bers):\n",
    "                for fold_i, fold in enumerate(folds):\n",
    "                    model = torch.load(base_dir + model_path + dataset)\n",
    "                    model = model.float().eval().to(device)\n",
    "                    injector = Injector(ber, param_names = ['mlp', 'fc', 'afm'], device = device, verbose = False, mitigation = 'SBP')\n",
    "                    injector.perform_mitigation(injector)\n",
    "                    injector.inject(model)\n",
    "                    del injector\n",
    "                    result = test(model, test_data_loader, device)\n",
    "                    print(cnt, result)\n",
    "                    results[model_path_i][dataset_i][ber_i][fold_i] = result\n",
    "                    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
